{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdb6836e",
   "metadata": {},
   "source": [
    "# Weak and Strong Scaling — Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b99398",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "BASE_RESULTS_DIR = Path(\"results\")\n",
    "BASE_RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CPU_CORES_PER_NODE = 128\n",
    "GPUS_PER_NODE = 4\n",
    "BASE_EFF_NPROCS = 2  # baseline n=2 para split/dist/sd/total\n",
    "\n",
    "# -----------------------------\n",
    "# Utils\n",
    "# -----------------------------\n",
    "def savefig(results_dir, name):\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_dir / f\"{name}.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "def ceil_div(a, b):\n",
    "    return int(math.ceil(float(a) / float(b)))\n",
    "\n",
    "def add_nodes_col(df_like):\n",
    "    df_like = df_like.copy()\n",
    "    def _calc_nodes(row):\n",
    "        dev = str(row[\"device\"]).lower()\n",
    "        if dev == \"cpu\":\n",
    "            return ceil_div(row[\"num_procs\"], CPU_CORES_PER_NODE)\n",
    "        else:\n",
    "            return ceil_div(row[\"num_procs\"], GPUS_PER_NODE)\n",
    "    df_like[\"nodes\"] = df_like.apply(_calc_nodes, axis=1)\n",
    "    return df_like\n",
    "\n",
    "def _pooled_mean_std(values, stds, weights):\n",
    "    m = np.asarray(values, float)\n",
    "    s = np.asarray(stds,   float)\n",
    "    w = np.asarray(weights, float)\n",
    "    mask = np.isfinite(m) & np.isfinite(s) & np.isfinite(w) & (w > 0)\n",
    "    m, s, w = m[mask], s[mask], w[mask]\n",
    "    if m.size == 0:\n",
    "        return None, None\n",
    "    N = np.sum(w)\n",
    "    mean_w = np.sum(w * m) / N\n",
    "    var_within = np.sum((w - 1.0) * (s ** 2.0))\n",
    "    var_between = np.sum(w * (m - mean_w) ** 2.0)\n",
    "    dof = max(N - 1.0, 1.0)\n",
    "    s_w = math.sqrt(max((var_within + var_between) / dof, 0.0))\n",
    "    return mean_w, s_w\n",
    "\n",
    "def combine_powers_2lines(g, mean_col, std_col, axis_col):\n",
    "    rows = []\n",
    "    for dev, d in g.groupby(\"device\"):\n",
    "        for x, dd in d.groupby(axis_col):\n",
    "            mw, sw = _pooled_mean_std(dd[mean_col], dd[std_col], dd[\"runs\"])\n",
    "            if mw is None:\n",
    "                continue\n",
    "            rows.append({\"device\": dev, axis_col: x, \"y_mean\": mw, \"y_std\": sw})\n",
    "    out = pd.DataFrame(rows)\n",
    "    return out.sort_values(axis_col)\n",
    "\n",
    "def combine_generic_2lines(g, y_col, ystd_col, axis_col):\n",
    "    g2 = g.rename(columns={y_col:\"mean_col\", ystd_col:\"std_col\"})\n",
    "    g2[\"runs\"] = g2.get(\"runs\", pd.Series([1]*len(g2)))\n",
    "    agg = combine_powers_2lines(g2, \"mean_col\", \"std_col\", axis_col)\n",
    "    return agg.rename(columns={\"y_mean\": y_col, \"y_std\": ystd_col})\n",
    "\n",
    "# >>> baseline-safe aggregator:\n",
    "# Garante que no ponto do eixo que coincide com o baseline (n_ref_procs=2 ou n_ref_nodes correspondente),\n",
    "# a média use SOMENTE as linhas de baseline. Assim, o valor plotado fica exatamente 1.\n",
    "def combine_perf_2lines_baseline_safe(g, y_col, ystd_col, axis_col, baseline_tags, base_tag):\n",
    "    enforce = (base_tag in baseline_tags)  # só força para split/dist/sd/total\n",
    "    rows = []\n",
    "    for dev, d in g.groupby(\"device\"):\n",
    "        for x, dd in d.groupby(axis_col):\n",
    "            sel = dd\n",
    "            if enforce:\n",
    "                if axis_col == \"num_procs\":\n",
    "                    if (dd[\"n_ref_procs\"] == x).any():\n",
    "                        sel = dd[dd[\"n_ref_procs\"] == x]\n",
    "                else:  # axis_col == \"nodes\"\n",
    "                    if (dd[\"n_ref_nodes\"] == x).any():\n",
    "                        sel = dd[(dd[\"n_ref_nodes\"] == x) & (dd[\"num_procs\"] == dd[\"n_ref_procs\"])]\n",
    "            mw, sw = _pooled_mean_std(sel[y_col], sel[ystd_col], sel[\"runs\"])\n",
    "            if mw is None:\n",
    "                continue\n",
    "            rows.append({\"device\": dev, axis_col: x, y_col: mw, ystd_col: sw})\n",
    "    out = pd.DataFrame(rows)\n",
    "    return out.sort_values(axis_col)\n",
    "\n",
    "# -----------------------------\n",
    "# Load & summarize\n",
    "# -----------------------------\n",
    "def prepare_data(csv_file, prefix, baseline_nprocs=BASE_EFF_NPROCS):\n",
    "    results_dir = BASE_RESULTS_DIR / prefix\n",
    "    results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = pd.read_csv(csv_file, parse_dates=[\"datetime\"])\n",
    "    # columns:\n",
    "    # datetime,power,total_particles,length_per_rank,num_procs,box_length,RAM_GB,gen_time,splitters_time,dist_time,total_time,device,seed,mode\n",
    "\n",
    "    counts = df.groupby([\"device\",\"power\",\"num_procs\"]).size()\n",
    "    print(f\"[{prefix}] Runs per configuration:\\n{counts}\")\n",
    "\n",
    "    summary = (\n",
    "        df.groupby([\"device\",\"power\",\"num_procs\"], as_index=False)\n",
    "          .agg(\n",
    "              gen_mean=(\"gen_time\",\"mean\"),           gen_std=(\"gen_time\",\"std\"),\n",
    "              split_mean=(\"splitters_time\",\"mean\"),   split_std=(\"splitters_time\",\"std\"),\n",
    "              dist_mean=(\"dist_time\",\"mean\"),         dist_std=(\"dist_time\",\"std\"),\n",
    "              total_mean=(\"total_time\",\"mean\"),       total_std=(\"total_time\",\"std\"),\n",
    "              runs=(\"total_time\",\"count\")\n",
    "          )\n",
    "    )\n",
    "    summary = add_nodes_col(summary)\n",
    "    summary[\"sd_mean\"] = summary[\"split_mean\"] + summary[\"dist_mean\"]\n",
    "    summary[\"sd_std\"]  = np.sqrt(np.maximum(summary[\"split_std\"]**2 + summary[\"dist_std\"]**2, 0.0))\n",
    "    for c in [\"gen_std\",\"split_std\",\"dist_std\",\"sd_std\",\"total_std\"]:\n",
    "        summary[c] = summary[c].fillna(0.0)\n",
    "\n",
    "    # --- Baselines ---\n",
    "    # (A) baseline n=2 por (device,power) — para split/dist/sd/total (speedup & efficiency)\n",
    "    base_dev2 = (\n",
    "        summary[summary[\"num_procs\"] == baseline_nprocs]\n",
    "          .rename(columns={\n",
    "              \"num_procs\":\"n_ref_procs\",\n",
    "              \"nodes\":\"n_ref_nodes\",\n",
    "              \"gen_mean\":\"gen_ref\",\"gen_std\":\"gen_ref_s\",\n",
    "              \"split_mean\":\"split_ref\",\"split_std\":\"split_ref_s\",\n",
    "              \"dist_mean\":\"dist_ref\",\"dist_std\":\"dist_ref_s\",\n",
    "              \"sd_mean\":\"sd_ref\",\"sd_std\":\"sd_ref_s\",\n",
    "              \"total_mean\":\"total_ref\",\"total_std\":\"total_ref_s\",\n",
    "          })[[\n",
    "              \"device\",\"power\",\"n_ref_procs\",\"n_ref_nodes\",\n",
    "              \"gen_ref\",\"gen_ref_s\",\"split_ref\",\"split_ref_s\",\n",
    "              \"dist_ref\",\"dist_ref_s\",\"sd_ref\",\"sd_ref_s\",\n",
    "              \"total_ref\",\"total_ref_s\"\n",
    "          ]]\n",
    "    )\n",
    "\n",
    "    # (B) baselines para generation:\n",
    "    #     - speedup: baseline CPU (menor num_procs por power)\n",
    "    #     - efficiency: baseline mínimo por (device,power)\n",
    "    cpu_only = summary[summary[\"device\"] == \"cpu\"].copy()\n",
    "    cpu_base_gen = (\n",
    "        cpu_only.sort_values([\"power\",\"num_procs\"])\n",
    "                .groupby(\"power\", as_index=False)\n",
    "                .first()\n",
    "                .rename(columns={\n",
    "                    \"num_procs\":\"cpu_base_nprocs\",\n",
    "                    \"gen_mean\":\"gen_cpu\",\"gen_std\":\"gen_cpu_s\"\n",
    "                })[[\"power\",\"cpu_base_nprocs\",\"gen_cpu\",\"gen_cpu_s\"]]\n",
    "    )\n",
    "    base_min_gen = (\n",
    "        summary.sort_values([\"device\",\"power\",\"num_procs\"])\n",
    "               .groupby([\"device\",\"power\"], as_index=False)\n",
    "               .first()\n",
    "               .rename(columns={\n",
    "                   \"num_procs\":\"n_ref_procs_min\",\n",
    "                   \"nodes\":\"n_ref_nodes_min\",\n",
    "                   \"gen_mean\":\"gen_ref_min\",\"gen_std\":\"gen_ref_s_min\"\n",
    "               })[[\"device\",\"power\",\"n_ref_procs_min\",\"n_ref_nodes_min\",\"gen_ref_min\",\"gen_ref_s_min\"]]\n",
    "    )\n",
    "\n",
    "    with_base = (summary\n",
    "        .merge(base_dev2, on=[\"device\",\"power\"], how=\"left\")\n",
    "        .merge(cpu_base_gen, on=\"power\", how=\"left\")\n",
    "        .merge(base_min_gen, on=[\"device\",\"power\"], how=\"left\")\n",
    "    )\n",
    "\n",
    "    # --- helpers ---\n",
    "    def ratio(a, b): \n",
    "        a = np.asarray(a, float); b = np.asarray(b, float)\n",
    "        out = np.full_like(a, np.nan, dtype=float)\n",
    "        ok = (b > 0) & np.isfinite(b)\n",
    "        out[ok] = a[ok] / b[ok]\n",
    "        return out\n",
    "\n",
    "    def ratio_std(a,sa,b,sb):\n",
    "        a = np.asarray(a, float); sa = np.asarray(sa, float)\n",
    "        b = np.asarray(b, float); sb = np.asarray(sb, float)\n",
    "        s = ratio(a,b)\n",
    "        out = np.full_like(s, np.nan, dtype=float)\n",
    "        ok = (a>0)&(b>0)&np.isfinite(a)&np.isfinite(b)\n",
    "        out[ok] = s[ok] * np.sqrt( (sa[ok]/a[ok])**2 + (sb[ok]/b[ok])**2 )\n",
    "        return out\n",
    "\n",
    "    # --- SPEEDUP ---\n",
    "    # split/dist/sd/total: baseline n=2 (speedup = T_ref(n=2)/T_n)\n",
    "    for tag, mcol, scol, rcol, rscol in [\n",
    "        (\"split\",\"split_mean\",\"split_std\",\"split_ref\",\"split_ref_s\"),\n",
    "        (\"dist\",\"dist_mean\",\"dist_std\",\"dist_ref\",\"dist_ref_s\"),\n",
    "        (\"sd\",\"sd_mean\",\"sd_std\",\"sd_ref\",\"sd_ref_s\"),\n",
    "        (\"total\",\"total_mean\",\"total_std\",\"total_ref\",\"total_ref_s\"),\n",
    "    ]:\n",
    "        with_base[f\"speedup_{tag}\"]   = ratio(with_base[rcol], with_base[mcol])\n",
    "        with_base[f\"speedup_{tag}_s\"] = ratio_std(with_base[rcol], with_base[rscol], with_base[mcol], with_base[scol])\n",
    "\n",
    "    # generation: baseline CPU (menor num_procs por power)\n",
    "    with_base[\"speedup_gen\"]   = ratio(with_base[\"gen_cpu\"], with_base[\"gen_mean\"])\n",
    "    with_base[\"speedup_gen_s\"] = ratio_std(with_base[\"gen_cpu\"], with_base[\"gen_cpu_s\"], with_base[\"gen_mean\"], with_base[\"gen_std\"])\n",
    "\n",
    "    # --- EFFICIENCY ---\n",
    "    # split/dist/sd/total: baseline n=2 (por processadores e por nós)\n",
    "    for tag, mcol, scol, rcol, rscol in [\n",
    "        (\"split\",\"split_mean\",\"split_std\",\"split_ref\",\"split_ref_s\"),\n",
    "        (\"dist\",\"dist_mean\",\"dist_std\",\"dist_ref\",\"dist_ref_s\"),\n",
    "        (\"sd\",\"sd_mean\",\"sd_std\",\"sd_ref\",\"sd_ref_s\"),\n",
    "        (\"total\",\"total_mean\",\"total_std\",\"total_ref\",\"total_ref_s\"),\n",
    "    ]:\n",
    "        ok = (with_base[\"n_ref_procs\"]>0) & (with_base[mcol]>0) & np.isfinite(with_base[mcol]) & np.isfinite(with_base[\"num_procs\"])\n",
    "        with_base.loc[ok, f\"eff_procs_{tag}\"] = (with_base.loc[ok, rcol] * with_base.loc[ok, \"n_ref_procs\"]) / (with_base.loc[ok, mcol] * with_base.loc[ok, \"num_procs\"])\n",
    "        with_base.loc[ok, f\"eff_procs_{tag}_s\"] = with_base.loc[ok, f\"eff_procs_{tag}\"] * np.sqrt(\n",
    "            (with_base.loc[ok, rscol] / with_base.loc[ok, rcol])**2 + (with_base.loc[ok, scol] / with_base.loc[ok, mcol])**2\n",
    "        )\n",
    "\n",
    "        ok2 = (with_base[\"n_ref_nodes\"]>0) & (with_base[mcol]>0) & np.isfinite(with_base[mcol]) & np.isfinite(with_base[\"nodes\"])\n",
    "        with_base.loc[ok2, f\"eff_nodes_{tag}\"] = (with_base.loc[ok2, rcol] * with_base.loc[ok2, \"n_ref_nodes\"]) / (with_base.loc[ok2, mcol] * with_base.loc[ok2, \"nodes\"])\n",
    "        with_base.loc[ok2, f\"eff_nodes_{tag}_s\"] = with_base.loc[ok2, f\"eff_nodes_{tag}\"] * np.sqrt(\n",
    "            (with_base.loc[ok2, rscol] / with_base.loc[ok2, rcol])**2 + (with_base.loc[ok2, scol] / with_base.loc[ok2, mcol])**2\n",
    "        )\n",
    "\n",
    "    # generation: baseline mínimo por (device,power)\n",
    "    okg = (with_base[\"n_ref_procs_min\"]>0) & (with_base[\"gen_mean\"]>0) & np.isfinite(with_base[\"gen_mean\"]) & np.isfinite(with_base[\"num_procs\"])\n",
    "    with_base.loc[okg, \"eff_procs_gen\"] = (with_base.loc[okg, \"gen_ref_min\"]*with_base.loc[okg, \"n_ref_procs_min\"])/(with_base.loc[okg, \"gen_mean\"]*with_base.loc[okg, \"num_procs\"])\n",
    "    with_base.loc[okg, \"eff_procs_gen_s\"] = with_base.loc[okg, \"eff_procs_gen\"] * np.sqrt(\n",
    "        (with_base.loc[okg, \"gen_ref_s_min\"]/with_base.loc[okg, \"gen_ref_min\"])**2 + (with_base.loc[okg, \"gen_std\"]/with_base.loc[okg, \"gen_mean\"])**2\n",
    "    )\n",
    "    okg2 = (with_base[\"n_ref_nodes_min\"]>0) & (with_base[\"gen_mean\"]>0) & np.isfinite(with_base[\"gen_mean\"]) & np.isfinite(with_base[\"nodes\"])\n",
    "    with_base.loc[okg2, \"eff_nodes_gen\"] = (with_base.loc[okg2, \"gen_ref_min\"]*with_base.loc[okg2, \"n_ref_nodes_min\"])/(with_base.loc[okg2, \"gen_mean\"]*with_base.loc[okg2, \"nodes\"])\n",
    "    with_base.loc[okg2, \"eff_nodes_gen_s\"] = with_base.loc[okg2, \"eff_nodes_gen\"] * np.sqrt(\n",
    "        (with_base.loc[okg2, \"gen_ref_s_min\"]/with_base.loc[okg2, \"gen_ref_min\"])**2 + (with_base.loc[okg2, \"gen_std\"]/with_base.loc[okg2, \"gen_mean\"])**2\n",
    "    )\n",
    "\n",
    "    return df, summary, with_base, results_dir\n",
    "\n",
    "# -----------------------------\n",
    "# Plots (2 lines: CPU & GPU)\n",
    "# -----------------------------\n",
    "def plot_time_vs_axis(summary, axis_col, file_tag, mean_col, std_col, results_dir, prefix):\n",
    "    agg = combine_powers_2lines(summary, mean_col, std_col, axis_col)\n",
    "    if agg.empty:\n",
    "        return\n",
    "    plt.figure(figsize=(9,5))\n",
    "    for dev, g in agg.groupby(\"device\"):\n",
    "        plt.errorbar(g[axis_col], g[\"y_mean\"], yerr=g[\"y_std\"], marker=\"o\", capsize=4, label=dev)\n",
    "    if axis_col == \"num_procs\":\n",
    "        plt.xscale(\"log\"); plt.xlabel(\"Processors (num_procs)\"); axis_name = \"procs\"\n",
    "    else:\n",
    "        plt.xlabel(\"Nodes\"); axis_name = \"nodes\"\n",
    "    ylabels = {\n",
    "        \"generation\":\"Generation time (s)\",\n",
    "        \"splitters\":\"Find splitters time (s)\",\n",
    "        \"distribution\":\"Data distribution time (s)\",\n",
    "        \"split_plus_dist\":\"Find+Distribution time (s)\",\n",
    "        \"total\":\"Total time (s)\"\n",
    "    }\n",
    "    plt.ylabel(ylabels.get(file_tag, \"Time (s)\"))\n",
    "    plt.title(f\"Time × {'processors' if axis_col=='num_procs' else 'nodes'} — {file_tag}\")\n",
    "    plt.grid(True, which=\"both\", ls=\":\")\n",
    "    plt.legend()\n",
    "    savefig(results_dir, f\"time_{axis_name}_{file_tag}_{prefix}\")\n",
    "\n",
    "def plot_speedup_vs_axis(with_base, axis_col, file_tag, base_tag, results_dir, prefix):\n",
    "    y  = f\"speedup_{base_tag}\"\n",
    "    ys = f\"speedup_{base_tag}_s\"\n",
    "    baseline_tags = {\"split\",\"dist\",\"sd\",\"total\"}\n",
    "    if base_tag in baseline_tags:\n",
    "        agg = combine_perf_2lines_baseline_safe(with_base, y, ys, axis_col, baseline_tags, base_tag)\n",
    "    else:\n",
    "        agg = combine_generic_2lines(with_base, y, ys, axis_col)\n",
    "    if agg.empty:\n",
    "        return\n",
    "    plt.figure(figsize=(9,5))\n",
    "    for dev, g in agg.groupby(\"device\"):\n",
    "        plt.errorbar(g[axis_col], g[y], yerr=g[ys], marker=\"o\", capsize=4, label=dev)\n",
    "    if axis_col == \"num_procs\":\n",
    "        plt.xscale(\"log\"); plt.xlabel(\"Processors (num_procs)\"); axis_name = \"procs\"\n",
    "    else:\n",
    "        plt.xlabel(\"Nodes\"); axis_name = \"nodes\"\n",
    "    plt.ylabel(\"Speedup\")\n",
    "    suffix = \"(baseline n=2)\" if base_tag in baseline_tags else \"(baseline min)\"\n",
    "    plt.title(f\"Speedup × {'processors' if axis_col=='num_procs' else 'nodes'} — {file_tag} {suffix}\")\n",
    "    plt.grid(True, which=\"both\", ls=\":\")\n",
    "    plt.legend()\n",
    "    savefig(results_dir, f\"speedup_{axis_name}_{file_tag}_{prefix}\")\n",
    "\n",
    "def plot_efficiency_vs_axis(with_base, axis_col, file_tag, base_tag, results_dir, prefix):\n",
    "    if axis_col == \"num_procs\":\n",
    "        y, ys = f\"eff_procs_{base_tag}\", f\"eff_procs_{base_tag}_s\"\n",
    "        axis_name, xlabel = \"procs\", \"Processors (num_procs)\"\n",
    "    else:\n",
    "        y, ys = f\"eff_nodes_{base_tag}\", f\"eff_nodes_{base_tag}_s\"\n",
    "        axis_name, xlabel = \"nodes\", \"Nodes\"\n",
    "\n",
    "    baseline_tags = {\"split\",\"dist\",\"sd\",\"total\"}\n",
    "    if base_tag in baseline_tags:\n",
    "        agg = combine_perf_2lines_baseline_safe(with_base, y, ys, axis_col, baseline_tags, base_tag)\n",
    "    else:\n",
    "        agg = combine_generic_2lines(with_base, y, ys, axis_col)\n",
    "\n",
    "    if agg.empty:\n",
    "        return\n",
    "    plt.figure(figsize=(9,5))\n",
    "    for dev, g in agg.groupby(\"device\"):\n",
    "        plt.errorbar(g[axis_col], g[y], yerr=g[ys], marker=\"o\", capsize=4, label=dev)\n",
    "    if axis_col == \"num_procs\":\n",
    "        plt.xscale(\"log\")\n",
    "    suffix = \"(baseline n=2)\" if base_tag in baseline_tags else \"(baseline min)\"\n",
    "    plt.xlabel(xlabel); plt.ylabel(\"Parallel efficiency\")\n",
    "    plt.title(f\"Parallel efficiency × {'processors' if axis_col=='num_procs' else 'nodes'} — {file_tag} {suffix}\")\n",
    "    plt.axhline(1.0, ls=\"--\", lw=1)\n",
    "    plt.grid(True, which=\"both\", ls=\":\")\n",
    "    plt.legend()\n",
    "    savefig(results_dir, f\"efficiency_{axis_name}_{file_tag}_{prefix}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Run for weak/strong\n",
    "# -----------------------------\n",
    "def run_all(csv_file, prefix):\n",
    "    df, summary, with_base, results_dir = prepare_data(csv_file, prefix)\n",
    "\n",
    "    # file_tag -> (mean_col, std_col, base_tag)\n",
    "    metrics = {\n",
    "        \"generation\":      (\"gen_mean\",   \"gen_std\",   \"gen\"),\n",
    "        \"splitters\":       (\"split_mean\", \"split_std\", \"split\"),\n",
    "        \"distribution\":    (\"dist_mean\",  \"dist_std\",  \"dist\"),\n",
    "        \"split_plus_dist\": (\"sd_mean\",    \"sd_std\",    \"sd\"),\n",
    "        \"total\":           (\"total_mean\", \"total_std\", \"total\"),\n",
    "    }\n",
    "\n",
    "    # Time × nodes / processors\n",
    "    for file_tag, (m, s, _b) in metrics.items():\n",
    "        plot_time_vs_axis(summary, \"nodes\",     file_tag, m, s, results_dir, prefix)\n",
    "        plot_time_vs_axis(summary, \"num_procs\", file_tag, m, s, results_dir, prefix)\n",
    "\n",
    "    # Speedup × nodes / processors\n",
    "    for file_tag, (_m, _s, base_tag) in metrics.items():\n",
    "        plot_speedup_vs_axis(with_base, \"nodes\",     file_tag, base_tag, results_dir, prefix)\n",
    "        plot_speedup_vs_axis(with_base, \"num_procs\", file_tag, base_tag, results_dir, prefix)\n",
    "\n",
    "    # Parallel efficiency × nodes / processors\n",
    "    for file_tag, (_m, _s, base_tag) in metrics.items():\n",
    "        plot_efficiency_vs_axis(with_base, \"nodes\",     file_tag, base_tag, results_dir, prefix)\n",
    "        plot_efficiency_vs_axis(with_base, \"num_procs\", file_tag, base_tag, results_dir, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa21cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_all(\"results_weak.csv\", \"weak\")\n",
    "run_all(\"results_strong.csv\", \"strong\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
